{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2dace4d-c4d6-4f23-a13b-6b09ece93b60",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XAS data validation by a simple machine learning model\n",
    "\n",
    "-----\n",
    "\n",
    "**Objective**: Train a computer to recognize when a measured spectrum looks like X-ray Absorption Spectroscopy (XAS) data.\n",
    "\n",
    "-----\n",
    "\n",
    "At my beamline, [BMM](https://www.bnl.gov/nsls2/beamlines/beamline.php?r=6-BM), we try to run 24 hours per day by relying upon robust instrumentation and well-tested automation. We have ways of lining up 10s of hours of data collection and letting the beamline run itself. From time to time, however, something goes wrong.  Maybe a detector fails ... maybe a sample has falls off the sample holder ... maybe the user tells the automation to do the wrong thing ... maybe gremlins overrun the beamline.  Who knows?\n",
    "\n",
    "Here is what we expect XAS data to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3df070-a972-4345-93f5-74e4b20463f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./static/ok_data.png', width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c28420-c0e8-49f1-8fbc-7e9366bc601d",
   "metadata": {},
   "source": [
    "But, sometimes something goes awray and we see garbage like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748af31f-423c-4e08-882a-58ef72b2bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./static/bad_data.png', width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3cb95-9b03-4149-b608-4f899b70336a",
   "metadata": {},
   "source": [
    "We need a simple sort of data evaluation.  My talk today is not about XAS data reduction ... nor anlaysis ... nor interpretation ....\n",
    "\n",
    "My plan is to show a way to flag a spectrum **as its measurement completes** as being either\n",
    "1. \"these data are probably OK\" or\n",
    "2. \"someone's attention is probably needed\"?\n",
    "\n",
    "My starting point is the basic observation is that this sort of identification problem is fundementally the same at the famous Iris Classification Problem &ndash; which is the \"Hello World!\" of machine learning.\n",
    "\n",
    "## The Iris Classification Problem\n",
    "\n",
    "In this classic problem, we work with a data set of observations of the morphology of the flowers of three species of iris:\n",
    "\n",
    "![irises](./static/irises.png)\n",
    "[(image source)](https://data-flair.training/blogs/iris-flower-classification/)\n",
    "\n",
    "**Sepal**: One of the usually green leaflike structures composing the outermost part of a flower. Sepals often enclose and protect the bud and may remain after the fruit form.\n",
    "\n",
    "**Petal**: One of the often brightly colored parts of a flower immediately surrounding the reproductive organs.\n",
    "\n",
    "Note that the shapes of the petals and sepals of these three species are different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aeb0d4-511c-4925-91d5-dd358e883b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn.datasets\n",
    "iris_set = sklearn.datasets.load_iris()\n",
    "\n",
    "i = pandas.DataFrame()\n",
    "i['sepal length'] = iris_set.data[:,0]\n",
    "i['sepal width']  = iris_set.data[:,1]\n",
    "i['petal length'] = iris_set.data[:,2]\n",
    "i['petal width']  = iris_set.data[:,3]\n",
    "i['target']       = iris_set.target\n",
    "i['species']      = iris_set.target_names[iris_set.target]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013600f-4c1f-4f01-9ee1-0a3600025f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris_set.target_names[int(i)])\n",
    "\n",
    "plt.scatter(i['petal length'], i['petal width'], c=i['target'])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('petal width')\n",
    "plt.title(\"Classification: Petal measurements\")\n",
    "## plotting credit: http://stephanie-w.github.io/brainscribble/classification-algorithms-on-iris-dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d43f5-08c4-4d5a-84ed-8b75a025060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(i['sepal length'], i['sepal width'], c=i['target'])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.title(\"Classification: Sepal measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba3eaf-f130-43b8-bca3-c8ef4454073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(i['petal width'], i['sepal length'], c=i['target'])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel('petal width')\n",
    "plt.ylabel('sepal length')\n",
    "plt.title(\"Classification: PW vs. SL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b6abe-26de-4c66-9c0f-4d4ddc07eac8",
   "metadata": {},
   "source": [
    "Thanks to nicely contrasting colors and the human brain's penchant for finding patterns, you can look at these representations of the iris dataset and see that the species cluster according to the dimensions of their sepals and petals.\n",
    "\n",
    "Remember that these pictures are 2-dimensional samplings of a 4-dimensional space of sepal and petal measurements.  There are 6 such 2D samplings.  The actual clustering in this data set should be considered on a 4D manifold.\n",
    "\n",
    "Now, imagine picking a new iris of unknown species with the intent of identifying it.  You might measure the length and width of its sepal and petal and drop the new measurement onto that 4D manifold.  The idea is to determine its species on the basis of the nearby, tagged data points.\n",
    "\n",
    "To implement this in numbers (as opposed to human perception), we'll use an algorithm called \"K Nearest Neighbors\" (KNN).  To explain KNN, I'll simply plagiarize Wikipedia:\n",
    "\n",
    "![KNN](./static/KnnClassification.svg)\n",
    "[(image source)](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "\n",
    "Quoth Wikipedia: \"The test sample (green dot) should be classified either to blue squares or to red triangles. If k = 3 (solid line circle) it is assigned to the red triangles because there are 2 triangles and only 1 square inside the inner circle. If k = 5 (dashed line circle) it is assigned to the blue squares (3 squares vs. 2 triangles inside the outer circle).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f745fa2-3224-4022-998e-db3016c51635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(i[['sepal length', 'sepal width', 'petal length', 'petal width']], i['target'], random_state=0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c292d0-2a16-4d81-bc21-1a8904cfbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46390ce0-3bcd-44e1-903f-8043e7bcdb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29592546-5e98-404e-9798-dc2829725362",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908155e-1e90-4d47-8977-96a2e4462be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c63361-ca97-4d95-9b33-dcb46f05256b",
   "metadata": {},
   "source": [
    "Here is the documentation from scikit-learn on the iris dataset:\n",
    "https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html and for more information, follow the other links cited above.\n",
    "\n",
    "So ... how does a fun botany problem relate to XAS?\n",
    "\n",
    "## Classifying XAS spectra\n",
    "\n",
    "Let's start by importing modules, fetching a catalog of data from Tiled, and defining some variables and utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf84001-ca16-41a4-8d52-3974c3bf39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "## create BMM's tiled catalog\n",
    "from tiled.client import from_uri\n",
    "c = from_uri(\"https://tiled-demo.blueskyproject.io/api\")\n",
    "cat=c['bmm']['raw']\n",
    "\n",
    "## Import the UIDs and human-assigned scores for the training corpus from files in ./data/\n",
    "with open('./data/training_set') as infile:\n",
    "    uids = infile.read().split('\\n')\n",
    "uids_of_training_set = [x for x in uids if (len(x) > 1)]\n",
    "\n",
    "import json, itertools\n",
    "with open(\"./data/tags.json\") as infile:\n",
    "    tags = json.load(infile)\n",
    "\n",
    "## a couple of utility functions for munging UID strings    \n",
    "def full_uid(short):\n",
    "    for u in uids_of_training_set:\n",
    "        if u[-8:] == short:\n",
    "            return u\n",
    "    return None    \n",
    "def short_uid(full):\n",
    "    return full[-8:]\n",
    "\n",
    "## import from CSV files\n",
    "def fetch_xas_scan_from_csv(uid):\n",
    "    fname = uid + '.csv'\n",
    "    data = pandas.read_csv(os.path.join(\"data\", \"ML_corpus\", fname))\n",
    "    data.plot(\"dcm_energy\", \"xmu\", xlabel='Energy (eV)', ylabel='$\\mu$(E)')\n",
    "\n",
    "## import from tiled\n",
    "def fetch_xas_scan(uid, type='fluorescence', plot=True):\n",
    "    if len(uid) < 10:\n",
    "        uid = full_uid(uid)\n",
    "    if uid is None:\n",
    "        print(\"not a valid UID\")\n",
    "        return\n",
    "    data = cat[uid].primary.read()\n",
    "    \n",
    "    ## apply knowledge of BMM databroker records to contruct mu(E) from xarray columns\n",
    "    if type == 'transmission':                             # tranmission data\n",
    "        data['xmu'] = numpy.log(data['I0']/data['It'])\n",
    "    elif 'xs' in cat[uid].metadata['start']['detectors']:  # fluorescence with Xspress3\n",
    "        elem = cat[uid].metadata['start']['XDI']['Element']['symbol']\n",
    "        data['xmu'] = (data[elem+'1']+data[elem+'2']+data[elem+'3']+data[elem+'4'])/data['I0']\n",
    "    else:                                                  # fluorescence, analog readout, prior to Xspress3\n",
    "        if cat[uid].metadata['start']['XDI']['Element']['symbol'] == 'Fe':\n",
    "            data['xmu'] = (data['DTC1']+data['DTC2']+data['DTC3']+data['DTC4'])/data['I0']\n",
    "        elif cat[uid].metadata['start']['XDI']['Element']['symbol'] == 'Ti':\n",
    "            data['xmu'] = (data['DTC2_1']+data['DTC2_2']+data['DTC2_3']+data['DTC2_4'])/data['I0']\n",
    "        elif cat[uid].metadata['start']['XDI']['Element']['symbol'] == 'Ce':\n",
    "            data['xmu'] = (data['DTC3_1']+data['DTC3_2']+data['DTC3_3']+data['DTC3_4'])/data['I0']\n",
    "            \n",
    "    if plot is True:\n",
    "        plt.xlabel('Energy (eV)')\n",
    "        plt.gca().set_ylabel('$\\mu$(E)')\n",
    "        plt.plot(data['dcm_energy'], data['xmu'])\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7294b6-1a66-443d-b53f-65e7f8ea7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uids_of_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587dfb4e-6ddd-4548-9b8e-f1811a2f2f08",
   "metadata": {},
   "source": [
    "Most of the data from this presentation is taken from a weekend in mid-2021 -- during time-of-covid, when all the experiments at BMM were mail-in, and at a moment when I was monitoring the beamline from home.  Being a nice weekend day, I set many hours of data collection running and then walked away.\n",
    "\n",
    "### Data, good and bad\n",
    "\n",
    "That weekend, I was working on ceramic samples from colleagues at the University of Sheffield. We were measuring XAS on the iron, cerium, and titanium edges.\n",
    "\n",
    "Here are some examples of reasonable data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0ebf4-41ea-4af3-906f-d3c5a3b49d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a good one (Fe)\n",
    "this=fetch_xas_scan('4de69926')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c2bd4-f1a8-438b-bf02-e50a2446affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a good one (Ce)\n",
    "this=fetch_xas_scan('4f3c2372')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378b33e-b2d1-40ba-bbcf-613c09454b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good one (Ti)\n",
    "this=fetch_xas_scan('6916040c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d667f0-118b-4bee-be93-37d1b4bff202",
   "metadata": {},
   "source": [
    "At some point during the weekend, something ... **BAD** ... happened. In truth, I don't quite remember the exact details, but here's the gist.  At the time, we were using a analog electronics to read the pulse trains from the detector and send those signals into VME scalar. Something in that signal chain got into a bad state such that the pulses were not being read cleanly.\n",
    "\n",
    "This went on for something like 10 hours, measuring garbage, before I finally noticed.\n",
    "\n",
    "Here are a couple of examples of **BAD** data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc75a3c-2553-40fa-aeb4-f7bc2154b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a bad one\n",
    "this = fetch_xas_scan('88b9e311')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b56634-1ca7-42b6-a29d-8d6a5fbd06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## another bad one\n",
    "this = fetch_xas_scan('64887ce3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afefd0-9043-439f-af20-958b1f36d629",
   "metadata": {},
   "source": [
    "### Preparing the training data\n",
    "\n",
    "This is a \"supervised learning\" problem.  That means that a human (me!) goes through the training data and tags each spectrum as *good* or *bad*.  \n",
    "\n",
    "The data, taken from BMM's DataBroker, were measured between July 9 and July 13 in 2020. These data are made available by the tiled demo server, like so:\n",
    "\n",
    "```python\n",
    "from tiled.client import from_uri\n",
    "c = from_uri(\"https://tiled-demo.blueskyproject.io/api\")\n",
    "cat=c['bmm']['raw']\n",
    "```\n",
    "\n",
    "The variable `cat` contains a catalog of DataBroker entries measured at BMM.  For those familiar with `bluesky`, the records in `cat` are much the same as what you would get by querying DataBroker directly from the `bluesky` command line, like so:\n",
    "\n",
    "```python\n",
    "measurement = db[uid]\n",
    "```\n",
    "\n",
    "The UIDs for the training data are listed in [this file](./data/training_set).\n",
    "\n",
    "I wrote a simple shell script that stepped through each spectrum in the training set, displayed a plot of each spectrum, and prompted me for a score for each spectrum.\n",
    "\n",
    "**\"good data\"**: score = 1, i.e. a spectrum that looked to my human eye like it stepped up then wiggled.\n",
    "\n",
    "**\"bad data\"**: score = 0, i.e. a spectrum that looked to my human eye like it **did not** step up then wiggle.\n",
    "\n",
    "(Side note: human tagging of a data set is tedious and error prone.  An ideal model would be tolerant of errors in the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7db54d-fad0-404f-9e87-3b8b77071558",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=8\n",
    "print(f'There are {len(uids_of_training_set)} UIDs in the training set.  Here are the first {n}:\\n')\n",
    "uids_of_training_set[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13d02b-af1b-480e-904a-88445d51930e",
   "metadata": {},
   "source": [
    "The scoring of the test (i.e. 1/0 for good/bad) was saved as [a JSON file](./data/ML_corpus/tags.json). Let's see what the first eight entries in that JSON file look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716ba20-ac77-4104-88bb-7d238d41be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(itertools.islice(tags.items(),  1, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbabc9-4f45-4778-a23f-75a521528ee7",
   "metadata": {},
   "source": [
    "Let's do a spot check on one of the good ones (`04fed2c6` == `'aedf4b8d-b6cb-4939-8e06-5ef704fed2c6'`) and on one of the bad ones (`0920716b` == `'f2acb042-033e-40b3-a4ac-a4d70920716b'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae8f53-91fa-4dbc-bade-dcc1235585a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "this=fetch_xas_scan('04fed2c6') # this one is tagged as \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac02136-ce79-4100-9a77-1414e301a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "this=fetch_xas_scan('0920716b') # this one is tagged as \"bad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016c733-5a84-4465-9779-bd49064a6274",
   "metadata": {},
   "source": [
    "Great!  Now we can start constructing our training set.\n",
    "\n",
    "First thing: we need to \"rationalize\" the data. The classifier expects all the data to be the same size -- for example, each observation of an iris had 4 data points (width and length of sepal and petal).  Similarly, the XAS spectra in our training set need to have the same number of energy points. Because different scans mght have different numbers of energy point, we will interpolate all the data onto a 401-point grid which is evenly spaced across the energy range of the original XAS scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56d3b1-5bd6-4a1f-aaa8-c9fdde514cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def rationalize_mu(en, mu):\n",
    "    '''Return energy and mu as a Pandas dataframe with data interpolated onto \n",
    "    a \"rationalized\" grid of equally spaced points.  GRIDSIZE = 401\n",
    "    '''\n",
    "    GRIDSIZE = 401\n",
    "    ee=list(numpy.arange(en[0], en[-1], (en[-1]-en[0])/GRIDSIZE))\n",
    "    mm=numpy.interp(ee, en, mu)\n",
    "    if len(ee) > GRIDSIZE:\n",
    "        ee = ee[:-1]\n",
    "        mm = mm[:-1]\n",
    "    df = pandas.DataFrame()\n",
    "    df['dcm_energy'] = ee\n",
    "    df['xmu'] = mm\n",
    "    return(df)\n",
    "\n",
    "def plot_rationalized_data(data, rat):\n",
    "    '''Make a quick-n-dirty plot of the original data overplotted by the data\n",
    "    interpolated onto a 401-point grid.\n",
    "    '''\n",
    "    plt.xlabel('Energy (eV)')\n",
    "    plt.gca().set_ylabel('$\\mu$(E)')\n",
    "    plt.plot(data[\"dcm_energy\"], data[\"xmu\"], label='original')\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    rat.plot(\"dcm_energy\", \"xmu\", xlabel='Energy (eV)', ylabel='$\\mu$(E)', label='rationalized', ax=ax)\n",
    "\n",
    "data = fetch_xas_scan('04fed2c6', plot=False)\n",
    "data_rational = rationalize_mu(data['dcm_energy'], data['xmu'])\n",
    "plot_rationalized_data(data, data_rational)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e09656-10b5-4505-916d-939f5f6431d2",
   "metadata": {},
   "source": [
    "And here's a bad one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84851752-f6fa-4c94-ae96-5b389f8fe182",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_xas_scan('0920716b', plot=False)\n",
    "data_rational = rationalize_mu(data['dcm_energy'], data['xmu'])\n",
    "plot_rationalized_data(data, data_rational)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15355b19-f82f-46b7-ad22-b27255f9f945",
   "metadata": {},
   "source": [
    "### Training and testing the model\n",
    "\n",
    "Almost ready!  Now, we need to import the entire tagged learning corpus into a form ready to be consumed by the sklearn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a22a3-3a21-4b76-a925-c6428213b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "\n",
    "from simple_progress_bar import update_progress\n",
    "corpus = []\n",
    "scores = []\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for i,f in enumerate(uids_of_training_set):\n",
    "    try:\n",
    "        data = fetch_xas_scan(f, plot=False)\n",
    "        data_rational = rationalize_mu(data['dcm_energy'], data['xmu'])\n",
    "        if short_uid(f) in tags:\n",
    "            corpus.append(list(data_rational['xmu']))\n",
    "            scores.append(tags[short_uid(f)])\n",
    "    except:\n",
    "        pass\n",
    "    update_progress(i / len(uids_of_training_set))\n",
    "update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18227d1d-5fa2-49cd-9a4f-ba74ac840655",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus), len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0e84f-a248-48e2-8640-31b61e1af3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "clf=KNeighborsClassifier(n_neighbors=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, scores, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47bb5b-fd6a-4b3a-b54a-d9709542fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856e30d-8ce4-43f1-8c56-00db40df53ec",
   "metadata": {},
   "source": [
    "97% success on the training set!  Not bad for an extremely naive approach to the problem.  Let's see if we can't improve upon this without having to do too much more work.\n",
    "\n",
    "[SciKit Learn](https://scikit-learn.org/stable/index.html) comes with a rather enormous number of\n",
    "[supervised learning models](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Let's try another one ... [a random forest classifier](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-tree).\n",
    "\n",
    "This model is based on \"decision trees\".  In short, the model asks a sequence of abstract questions about the data &ndash; essentially \"does this data point look like it's from good data or bad data?\"  It makes some number of such decision trees and has them all vote on whether an unknown should be categorized as good data or bad.  (See [here](https://www.ibm.com/cloud/learn/random-foresthttps://www.ibm.com/cloud/learn/random-forest) for a much better explanation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3ca2f-04f5-481e-bfae-b4c68471f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb6679-a090-42d9-be54-83a09ffb2051",
   "metadata": {},
   "source": [
    "Complete success?!?  Woot!  Now we're gettin' somewhere!\n",
    "\n",
    "We are already starting to push up against my dilettante's knowledge of machine learning. A more informed choice of classifier can be made (and was, by Phil, in the paper a group of us here at NSLS-II just got published), but let's plow ahead using our random forest.\n",
    "\n",
    "To get a sense of how this works, let's look at the first item in the test portion of the training set.  We'll check how I tagged it, see what it looks like when plotted, and see how it evaluates using the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb700fc5-9821-4df3-bbd6-d58891901d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97108e17-31a7-4518-b0ec-2d58843d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a39faf-9172-4ba7-ab70-4ca247425253",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X_test[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d48b8c-18c2-4acc-8047-d585369c70a8",
   "metadata": {},
   "source": [
    "The `predict` function returns a 1 or a 0 on the basis of its evaluation of the supplied test data.  In this case, the model and I agree about these data. Yay!\n",
    "\n",
    "Let's try it on a spectrum not in the training set! Here's an Fe edge spectrum measured on a completely different sample from a completely different area of science which was measured at BMM over a year later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b92db-6a0e-4776-bbeb-1a86b3d09bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = fetch_xas_scan('89353743-7c9a-4d4b-8f2a-34673e69a361', plot=False)\n",
    "unknown_rational = rationalize_mu(unknown['dcm_energy'], unknown['xmu'])\n",
    "plot_rationalized_data(unknown, unknown_rational)\n",
    "#unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7948fa-3c8d-468e-8cf4-651332fd45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([list(unknown_rational['xmu'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df09490-c9a3-41db-a394-547ca343bed3",
   "metadata": {},
   "source": [
    "Splendid!  A visual inspection tells us that the new spectrum looks like XAS data and our model agrees!\n",
    "\n",
    "## Using our model\n",
    "\n",
    "Once our model is created, we can follow sklearn's hints about [model persistence](https://scikit-learn.org/stable/modules/model_persistence.html).  The model gets serialized to a [joblib](https://joblib.readthedocs.io/en/latest/persistence.html) file.  The file containing the model serialization is part of the [bluesky profile at BMM](https://github.com/NSLS-II-BMM/profile_collection).  Thus this machine learning model is always available and ready to be integrated into our operations.\n",
    "\n",
    "In practice, we compare *every* spectrum measured against our model.  The plan we use to measure an XAS spectrum includes a loop over the numbr of repetitions reqeusted by the user.  As part of that loop, the data that just finished are rationalized as discussed above and scored by the model.\n",
    "\n",
    "At BMM, we use Slack to provide feedback to users and staff during the experiment.  In the screenshot below, you can see the result of the data evaluation for each of two repetitions on that sample.  At the end of the two repetitions, the data are merged and lightly process, then a picture of the data are posted to Slack.\n",
    "\n",
    "![Slack+ML](./static/slack+ml.png)\n",
    "\n",
    "In this way, user and staff are given a hint about whether the experiment is progressing generally well or not.\n",
    "\n",
    "## Improving the model\n",
    "\n",
    "In practice, the model developed in this tutorial is not strong enough for general use.  Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c024cd-1183-4cae-80df-dd50a5bcb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure = fetch_xas_scan('10cefec0-8239-458d-9cb8-3f8aa371ce79', plot=False)\n",
    "failure_rational = rationalize_mu(failure['dcm_energy'], failure['xmu'])\n",
    "plot_rationalized_data(failure, failure_rational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c9ae2-046a-4ecd-966a-75c90604923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([list(failure_rational['xmu'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d54aa5-8c1e-4e1a-9846-9a71453fa1df",
   "metadata": {},
   "source": [
    "Poop!\n",
    "\n",
    "Those As edge data are obviously excellent data, but the model in its current state does not recognize that.\n",
    "\n",
    "Over time, I have tagged more data and added them to the model.  The model in use at BMM is still not perfect. False negatives are, by far, the more common failure. Just last week, I instrumented BMM's profile to log the UID of every scan that fails the data evaluation so that I can correctly tag the spectrum and add it to the training set.  Hopefully, over time, the model will become robust against all actual XAS data measured at BMM.\n",
    "\n",
    "Reliablility in the high 90s still means that every day, a user will ask me \"Why did the data evaluation fail? What's wrong with my data?\"  Sigh....\n",
    "\n",
    "The actual implementation of this machine learning model at BMM is contained in [this file](https://github.com/NSLS-II-BMM/profile_collection/blob/master/startup/BMM/ml.py) from [BMM's profile](https://github.com/NSLS-II-BMM/profile_collection). It's use upon conclusion of an XAFS scan and the posting of the result to Slack is shown [here](https://github.com/NSLS-II-BMM/profile_collection/blob/master/startup/BMM/xafs.py#L986-L995https://github.com/NSLS-II-BMM/profile_collection/blob/master/startup/BMM/xafs.py#L986-L995).\n",
    "\n",
    "-----\n",
    "\n",
    "As a closing comment, I want to advertise a little project of mine.\n",
    "\n",
    "Bluesky by Example (https://nsls-ii-bmm.github.io/bluesky-by-example/) is Bluesky documentation by and for beamline staff.  Maybe you'll find something helpful there.  \n",
    "\n",
    "Or..... Maybe you have something helpful *to contribute*.  Please fork the repo and make a PR to add your own example.  This presentation will eventually become a chapter.\n",
    "\n",
    "![BBE](./static/bluesky-by-example.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd941e2-3c9f-41f1-a610-438f44d15003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
